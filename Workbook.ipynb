{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: LRU Cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick recap on the solution requirements and what this translates into for usage of data structures. To achieve get & put operations in constant time (O(1)), I'm going to use a hashmap. In addition, removing the oldest item when the cache is full is required in constant time as well, thus I cannot use a simple array/list, as e.g. removing at the head and inserting in the tail, would lead to index updating which is not a constant operation. I'm going to implement this part as a queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your work here\n",
    "# Creating a node class for the queue\n",
    "class Node:\n",
    "    def __init__(self, key, value):\n",
    "        # My Node class receives and holds inputs (key and value) as well as pointers for the next and previous nodes, respectively\n",
    "        self.key = key\n",
    "        self.value = value\n",
    "        self.prev = None\n",
    "        self.next = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a LRU Cache data structure\n",
    "class LRU_Cache(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        # Initialize class variables, starting with a hashmap using Python's dict object as well as variable for current list lengt\n",
    "        self.hashmap = {}\n",
    "        self.num_entries = 0\n",
    "        # Including a head and tail parameter here instead own class\n",
    "        self.head = None\n",
    "        self.tail = None\n",
    "        # Place an upper bound on the size of the cache\n",
    "        self.cap = capacity\n",
    "\n",
    "    def get(self, key):\n",
    "        \"\"\" \n",
    "        Options to handle:\n",
    "        - Cache hit: head or not; update head if not\n",
    "        - Cache miss\n",
    "        \"\"\"\n",
    "        # Retrieve item from provided key. Return -1 if nonexistent. \n",
    "        # Cache hit\n",
    "        if key in self.hashmap:\n",
    "            # Case 1: it's the head\n",
    "            node = self.hashmap[key]\n",
    "            if node == self.head:\n",
    "                return node.value\n",
    "            # Case 2: not head, needs to become new head\n",
    "            else:\n",
    "                # Delete node for current position (!= head)\n",
    "                self.delete(node)\n",
    "                # Set selected node as new head\n",
    "                self.set_head(node)\n",
    "                return node.value      \n",
    "        \n",
    "        # Cache miss\n",
    "        if key not in self.hashmap:\n",
    "            return -1\n",
    "\n",
    "    def put(self, key, value):\n",
    "        \"\"\"\n",
    "        Options to handle:\n",
    "        - Check Capacity\n",
    "        \n",
    "        \"\"\"\n",
    "        # If cache is at capacity remove the oldest item.\n",
    "        if self.num_entries == 5:\n",
    "            self.delete_tail()\n",
    "            self.num_entries -= 1\n",
    "        elif self.cap <= 0:\n",
    "            raise ValueError(\"Capacity is too low. It must be above 0!\")\n",
    "        \n",
    "        new_node = Node(key,value)\n",
    "        \n",
    "        # If cache is empty, start new one as linked list\n",
    "        if self.num_entries == 0:\n",
    "            self.head = new_node\n",
    "            self.tail = new_node\n",
    "            self.hashmap[key] = new_node\n",
    "            self.num_entries += 1\n",
    "            return\n",
    "        \n",
    "        # Set the value if key is not present in the cache.\n",
    "        if key not in self.hashmap:\n",
    "            self.set_head(new_node)\n",
    "            self.hashmap[key] = new_node\n",
    "        \n",
    "        # Update the value if key is present in the cache.\n",
    "        if key in self.hashmap:\n",
    "            current_node = self.hashmap[key]\n",
    "            current_node.value = value\n",
    "        # Check if current node is already head node, update if not\n",
    "            if self.head != current_node:\n",
    "                self.delete(current_node)\n",
    "                self.set_head(current_node)\n",
    "     \n",
    "    def set_head(self, node):\n",
    "        # Set current node to head node\n",
    "        # Update pointers\n",
    "        # Check if there is a head already\n",
    "        if not self.head:\n",
    "            self.head = node\n",
    "            self.tail = node\n",
    "        # If self.head is already defined, update pointer and set new head\n",
    "        else:\n",
    "            node.prev = self.head\n",
    "            self.head.next = node\n",
    "            self.head = node\n",
    "            \n",
    "        self.num_entries += 1\n",
    "           \n",
    "    def delete(self, node):\n",
    "        # Delete node and update pointers\n",
    "        # Check if there is a head at all\n",
    "        if not self.head:\n",
    "            return\n",
    "        \n",
    "        # If self.head is already set, but there are no pointer to prev and next (case with one node that is head & tail)\n",
    "        # Reset head/tail\n",
    "        if not node.next and not node.prev:\n",
    "            self.head = None\n",
    "            self.tail = None\n",
    "        \n",
    "        # Case for node being a middle node\n",
    "        if node.next:\n",
    "            node.next.prev = node.prev\n",
    "        if node.prev:\n",
    "            node.prev.next = node.next\n",
    "            \n",
    "        # Case for node being the tail node\n",
    "        if self.tail == node:\n",
    "            self.delete_tail()\n",
    "        \n",
    "        self.num_entries -= 1\n",
    "        \n",
    "    def delete_tail(self):\n",
    "        # Delete key in hashmap first\n",
    "        del self.hashmap[self.tail.key]\n",
    "        # Delete/ Update tail and pointer\n",
    "        node = self.tail.next\n",
    "        node.prev = None\n",
    "        self.tail = node\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "-1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing\n",
    "our_cache = LRU_Cache(5)\n",
    "\n",
    "our_cache.put(1, 1);\n",
    "our_cache.put(2, 2);\n",
    "our_cache.put(3, 3);\n",
    "our_cache.put(4, 4);\n",
    "\n",
    "\n",
    "print(our_cache.get(1))       # returns 1\n",
    "print(our_cache.get(2))       # returns 2\n",
    "print(our_cache.get(9))      # returns -1 because 9 is not present in the cache\n",
    "\n",
    "our_cache.put(5, 5) \n",
    "our_cache.put(6, 6)\n",
    "\n",
    "our_cache.get(3)      # returns -1 because the cache reached it's capacity and 3 was the least recently used entry\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time complexity comments - Goal: All operations must take O(1) time.\n",
    "Due to the implementation using a hasmap/dict object as well as a linked list, all operations fullfil requirement of constant time complexity O(1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: File Recursion - Finding Files\n",
    "\n",
    "For this problem, the goal is to write code for finding all files under a directory (and all directories beneath it) that end with \".c\"\n",
    "\n",
    "Here is an example of a test directory listing, which can be downloaded:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ./testdir\n",
    "- ./testdir/subdir1\n",
    "- ./testdir/subdir1/a.c\n",
    "- ./testdir/subdir1/a.h\n",
    "- ./testdir/subdir2\n",
    "- ./testdir/subdir2/.gitkeep\n",
    "- ./testdir/subdir3\n",
    "- ./testdir/subdir3/subsubdir1\n",
    "- ./testdir/subdir3/subsubdir1/b.c\n",
    "- ./testdir/subdir3/subsubdir1/b.h\n",
    "- ./testdir/subdir4\n",
    "- ./testdir/subdir4/.gitkeep\n",
    "- ./testdir/subdir5\n",
    "- ./testdir/subdir5/a.c\n",
    "- ./testdir/subdir5/a.h\n",
    "- ./testdir/t1.c\n",
    "- ./testdir/t1.h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python's os module will be usefulâ€”in particular, you may want to use the following resources:\n",
    "\n",
    "os.path.isdir(path)\n",
    "\n",
    "os.path.isfile(path)\n",
    "\n",
    "os.listdir(directory)\n",
    "\n",
    "os.path.join(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def find_files(suffix, path):\n",
    "    \"\"\"\n",
    "    Find all files beneath path with file name suffix.\n",
    "\n",
    "    Note that a path may contain further subdirectories\n",
    "    and those subdirectories may also contain further subdirectories.\n",
    "\n",
    "    There are no limit to the depth of the subdirectories can be.\n",
    "\n",
    "    Args:\n",
    "      suffix(str): suffix if the file name to be found\n",
    "      path(str): path of the file system\n",
    "\n",
    "    Returns:\n",
    "       a list of paths\n",
    "    \"\"\"\n",
    "    # Create empty list to collect all correct paths\n",
    "    path_list = []\n",
    "    \n",
    "    # Create list of all elements in current path\n",
    "    dir_list = os.listdir(path)\n",
    "    \n",
    "    for element in dir_list:\n",
    "        # create full path of element\n",
    "        sub_path = path + \"/\" + element\n",
    "        # Option 1: Check if directory or not\n",
    "        if os.path.isdir(sub_path):\n",
    "            # recurse through sub directory if check is True\n",
    "            sub_list = find_files(suffix, sub_path)\n",
    "            # Check if function returns a file path for matching file, None if empty list\n",
    "            if sub_list != None:\n",
    "                path_list.extend(sub_list)\n",
    "        # Option 2: check if element is a file and if so, check suffix match\n",
    "        elif os.path.isfile(sub_path):\n",
    "            if element[-2:] == suffix:\n",
    "                path = os.path.join(path,element)\n",
    "                path_list.append(path)\n",
    "            else:\n",
    "                continue\n",
    "    \n",
    "    return path_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./testdir/subdir5/a.c',\n",
       " './testdir/subdir3/subsubdir1/b.c',\n",
       " './testdir/subdir1/a.c',\n",
       " './testdir/t1.c']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing\n",
    "find_files(\".c\",\"./testdir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['testdir.zip', '.ipynb_checkpoints', 'testdir', 'Workbook.ipynb', 'ex.py']\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "## Locally save and call this file ex.py ##\n",
    "\n",
    "# Code to demonstrate the use of some of the OS modules in python\n",
    "\n",
    "import os\n",
    "\n",
    "# Let us print the files in the directory in which you are running this script\n",
    "print (os.listdir(\".\"))\n",
    "\n",
    "# Let us check if this file is indeed a file!\n",
    "print (os.path.isfile(\"./ex.py\"))\n",
    "\n",
    "# Does the file end with .py?\n",
    "print (\"./ex.py\".endswith(\".py\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Huffman Coding\n",
    "\n",
    "A Huffman code is a type of optimal prefix code that is used for compressing data. The Huffman encoding and decoding schema is also lossless, meaning that when compressing the data to make it smaller, there is no loss of information.\n",
    "\n",
    "The Huffman algorithm works by assigning codes that correspond to the relative frequency of each character for each character. The Huffman code can be of any length and does not require a prefix; therefore, this binary code can be visualized on a binary tree with each encoded character being stored on leafs.\n",
    "\n",
    "There are many types of pseudocode for this algorithm. At the basic core, it is comprised of building a Huffman tree, encoding the data, and, lastly, decoding the data.\n",
    "\n",
    "Here is one type of pseudocode for this coding schema:\n",
    "\n",
    "- Take a string and determine the relevant frequencies of the characters.\n",
    "- Build and sort a list of tuples from lowest to highest frequencies.\n",
    "- Build the Huffman Tree by assigning a binary code to each letter, using shorter codes for the more frequent letters. (This is the heart of the Huffman algorithm.)\n",
    "- Trim the Huffman Tree (remove the frequencies from the previously built tree).\n",
    "- Encode the text into its compressed form.\n",
    "- Decode the text from its compressed form.\n",
    "\n",
    "\n",
    "You then will need to create encoding, decoding, and sizing schemas. You have to uniquely account for each ASCII code, i.e. you need to take care of -\n",
    "\n",
    "- Individual character of the string\n",
    "\n",
    "- All punctuation marks\n",
    "\n",
    "- Spaces\n",
    "\n",
    "- Lowercase and Uppercase\n",
    "\n",
    "Hint: You can solve the problem with mere `TreeNode` objects that have left and right pointers to other `TreeNode` objects. Having access to the root node let's you traverse the entire tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huffman Visualization!(https://people.ok.ubc.ca/ylucet/DS/Huffman.html)\n",
    "\n",
    "Tree Generator(http://huffman.ooz.ie/)\n",
    "\n",
    "Additional Explanation (https://www.siggraph.org/education/materials/HyperGraph/video/mpeg/mpegfaq/huffman_tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def huffman_encoding(data):\n",
    "    pass\n",
    "\n",
    "def huffman_decoding(data,tree):\n",
    "    pass\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    codes = {}\n",
    "\n",
    "    a_great_sentence = \"The bird is the word\"\n",
    "\n",
    "    print (\"The size of the data is: {}\\n\".format(sys.getsizeof(a_great_sentence)))\n",
    "    print (\"The content of the data is: {}\\n\".format(a_great_sentence))\n",
    "\n",
    "    encoded_data, tree = huffman_encoding(a_great_sentence)\n",
    "\n",
    "    print (\"The size of the encoded data is: {}\\n\".format(sys.getsizeof(int(encoded_data, base=2))))\n",
    "    print (\"The content of the encoded data is: {}\\n\".format(encoded_data))\n",
    "\n",
    "    decoded_data = huffman_decoding(encoded_data, tree)\n",
    "\n",
    "    print (\"The size of the decoded data is: {}\\n\".format(sys.getsizeof(decoded_data)))\n",
    "    print (\"The content of the encoded data is: {}\\n\".format(decoded_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4: Active Directory\n",
    "\n",
    "In Windows Active Directory, a group can consist of user(s) and group(s) themselves. We can construct this hierarchy as such. Where User is represented by str representing their ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Group(object):\n",
    "    def __init__(self, _name):\n",
    "        self.name = _name\n",
    "        self.groups = []\n",
    "        self.users = []\n",
    "\n",
    "    def add_group(self, group):\n",
    "        self.groups.append(group)\n",
    "\n",
    "    def add_user(self, user):\n",
    "        self.users.append(user)\n",
    "\n",
    "    def get_groups(self):\n",
    "        return self.groups\n",
    "\n",
    "    def get_users(self):\n",
    "        return self.users\n",
    "\n",
    "    def get_name(self):\n",
    "        return self.name\n",
    "\n",
    "\n",
    "parent = Group(\"parent\")\n",
    "child = Group(\"child\")\n",
    "sub_child = Group(\"subchild\")\n",
    "\n",
    "sub_child_user = \"sub_child_user\"\n",
    "sub_child.add_user(sub_child_user)\n",
    "\n",
    "child.add_group(sub_child)\n",
    "parent.add_group(child)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that provides an efficient look up of whether the user is in a group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_user_in_group(user, group):\n",
    "    \"\"\"\n",
    "    Return True if user is in the group, False otherwise.\n",
    "\n",
    "    Args:\n",
    "      user(str): user name/id\n",
    "      group(class:Group): group to check user membership against\n",
    "    \"\"\"\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5: Blockchain\n",
    "\n",
    "A Blockchain is a sequential chain of records, similar to a linked list. Each block contains some information and how it is connected related to the other blocks in the chain. Each block contains a cryptographic hash of the previous block, a timestamp, and transaction data. For our blockchain we will be using a SHA-256 hash, the Greenwich Mean Time when the block was created, and text strings as the data.\n",
    "\n",
    "Use your knowledge of linked lists and hashing to create a blockchain implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Blockchain Picture\n",
    "    \n",
    " We can break the blockchain down into three main parts. First is the information hash:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "def calc_hash(self):\n",
    "      sha = hashlib.sha256()\n",
    "\n",
    "      hash_str = \"We are going to encode this string of data!\".encode('utf-8')\n",
    "\n",
    "      sha.update(hash_str)\n",
    "\n",
    "      return sha.hexdigest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do this for the information we want to store in the block chain such as transaction time, data, and information like the previous chain.\n",
    "\n",
    "The next main component is the block on the blockchain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block:\n",
    "\n",
    "    def __init__(self, timestamp, data, previous_hash):\n",
    "      self.timestamp = timestamp\n",
    "      self.data = data\n",
    "      self.previous_hash = previous_hash\n",
    "      self.hash = self.calc_hash()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is an example of attributes you could find in a Block class.\n",
    "\n",
    "Finally you need to link all of this together in a block chain, which you will be doing by implementing it in a linked list. All of this will help you build up to a simple but full blockchain implementation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
